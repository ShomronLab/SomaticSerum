{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb21c20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### base\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import os\n",
    "\n",
    "# matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "# display\n",
    "from IPython.display import display\n",
    "\n",
    "# autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# fix random seed\n",
    "from numpy.random import seed as set_random_seed\n",
    "set_random_seed(42)\n",
    "\n",
    "# explainability\n",
    "# import shap, lime #eli5\n",
    "# shap.initjs()\n",
    "\n",
    "# debug\n",
    "# from icecream import ic\n",
    "# debug = ic\n",
    "import logging\n",
    "logg = logging.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de1961f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, re\n",
    "import argparse\n",
    "import time\n",
    "import random\n",
    "import logging\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch._C import device\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "from train import train\n",
    "from test import test\n",
    "from src.loader import CustomBamDataset2\n",
    "import src.util as util\n",
    "from src.util import Parms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a7406ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "root        : INFO     Logger initialized\n",
      "root        : INFO     Logger initialized\n",
      "root        : INFO     Logger initialized\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser('Train or test SomaticSerum model.')\n",
    "parser.add_argument('training_bam_dir', type=str,\n",
    "                    help='Train data bams directory')\n",
    "parser.add_argument('--sample_split', required=False, type=str,\n",
    "                    help='How to split the training data: True - by samples, False - by random on the entire dataset',\n",
    "                    default = 'True')\n",
    "parser.add_argument('--model', required=False, type=str, \n",
    "                    help='model', default='SimpleCnn')\n",
    "parser.add_argument('--hidden_size', required=False, type=int,\n",
    "                    help='The number of hidden units', default=64)\n",
    "parser.add_argument('--sequence_length', required=False, type=int,\n",
    "                    help='The length of the sequence', default=200)\n",
    "parser.add_argument('--batch_size', required=False, type=int,\n",
    "                    help='The size of each batch', default=512)\n",
    "parser.add_argument('--learning_rate', required=False, type=float,\n",
    "                    help='The learning rate value', default=0.00001)\n",
    "parser.add_argument('--max_epoch', required=False, type=int,\n",
    "                    help='The maximum epoch', default=100)\n",
    "parser.add_argument('--lstm_layers', required=False, type=int,\n",
    "                    help='Num of LSTM layers', default=10)\n",
    "parser.add_argument('--dropout', required=False, type=float,\n",
    "                    help='Dropout', default=0.5)\n",
    "parser.add_argument('--num_workers', required=False, type=int,\n",
    "                    help='Number of workers', default=1)\n",
    "parser.add_argument('--out', required=False, type=str,\n",
    "                    help='Output directory', default='output')\n",
    "parser.add_argument('--test', required=False, type=str,\n",
    "                    help='Test directory')\n",
    "# args = parser.parse_args()\n",
    "\n",
    "args = parser.parse_known_args()[0]\n",
    "args.__dict__.update(dict(\n",
    "        training_bam_dir=\"seqmerge/DLbams_rand\",\n",
    "        sample_split=True,\n",
    "        model=\"SimpleCnn\",\n",
    "        hidden_size=64,\n",
    "        batch_size=512,\n",
    "        learning_rate=0.00001,\n",
    "        max_epoch=100,\n",
    "        dropout=0.005,\n",
    "#         out=MassiveLoop3,\n",
    "    ))\n",
    "parms = Parms(\n",
    "    args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e9dc897",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "root        : INFO     Dataloading train\n",
      "root        : INFO     Dataloading train\n",
      "root        : INFO     Number of Normal reads: 159534, Number of Somatic reads: 168989. Ratio: 0.944\n",
      "root        : INFO     Number of Normal reads: 159534, Number of Somatic reads: 168989. Ratio: 0.944\n"
     ]
    }
   ],
   "source": [
    "full_train_dataset  = CustomBamDataset2(parms.BAM_DIR, out = parms.OUT, whichSet = 'train')\n",
    "train_size          = int(parms.TRAIN_VALIDATION_SPLIT * len(full_train_dataset))\n",
    "val_size            = len(full_train_dataset) - train_size\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(full_train_dataset, [train_size, val_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa7b4f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size = parms.BATCH_SIZE, shuffle = True, num_workers = parms.NUM_WORKERS)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size = parms.BATCH_SIZE, shuffle = True, num_workers = parms.NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "762f564a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "root        : INFO     Setting up the model...\n",
      "root        : INFO     Setting up the model...\n",
      "root        : INFO     Setting up the model...\n"
     ]
    }
   ],
   "source": [
    "# --- Model setup ----------------------------------------------------\n",
    "logging.info('Setting up the model...')\n",
    "nucleotide_model    = parms.return_model()\n",
    "loss_fn             = torch.nn.CrossEntropyLoss()\n",
    "model_params        = list(nucleotide_model.parameters())\n",
    "optimizer           = torch.optim.AdamW(model_params, lr=parms.LEARNING_RATE, eps=1e-08, weight_decay=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b466f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nucleotide_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d902414",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "root        : INFO     Setting up the model...\n",
      "root        : INFO     Setting up the model...\n"
     ]
    }
   ],
   "source": [
    "# --- Training -------------------------------------------------------\n",
    "logging.info('Setting up the model...')\n",
    "if torch.cuda.is_available():\n",
    "    nucleotide_model = nucleotide_model.cuda()\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "logg(device)\n",
    "\n",
    "if parms.TEST:\n",
    "    # Skip training\n",
    "    logging.info('Skipping train')\n",
    "    metric = pd.read_csv('{}/metric.csv'.format(parms.TEST))\n",
    "    name = '{}/{}'.format(parms.TEST, [f for f in os.listdir(parms.TEST) if f.endswith('.txt')][0].split('txt')[0])\n",
    "    model_path = \"{}/{}.pth\".format(parms.TEST, type(nucleotide_model).__name__)\n",
    "    metric_test = test(parms, model_path, test_dataloader, device, loss_fn)\n",
    "else:\n",
    "    logging.info('Training...')\n",
    "    history, name, metric, model_path = train(model = nucleotide_model,\n",
    "                                optimizer = optimizer,\n",
    "                                loss_fn = loss_fn,\n",
    "                                train_dl = train_dataloader,\n",
    "                                val_dl = valid_dataloader,\n",
    "                                epochs = parms.MAX_EPOCH,\n",
    "                                device = device,\n",
    "                                out = parms.OUT)\n",
    "    # Test\n",
    "    metric_test = test(parms, model_path, test_dataloader, device, loss_fn)\n",
    "\n",
    "# --- Plotting -------------------------------------------------------\n",
    "logging.info('Plotting...')\n",
    "util.plot(name, metric, metric_test, parms.OUT)\n",
    "\n",
    "# acc = history['acc']\n",
    "# val_acc = history['val_acc']\n",
    "# loss = history['loss']\n",
    "# val_loss = history['val_loss']\n",
    "# epochs = range(1, len(acc) + 1)\n",
    "\n",
    "logging.info(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1b01fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e04865",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
