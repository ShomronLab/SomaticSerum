{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb21c20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### base\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import os\n",
    "\n",
    "# matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "# display\n",
    "from IPython.display import display\n",
    "\n",
    "# autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# fix random seed\n",
    "from numpy.random import seed as set_random_seed\n",
    "set_random_seed(42)\n",
    "\n",
    "# explainability\n",
    "# import shap, lime #eli5\n",
    "# shap.initjs()\n",
    "\n",
    "# debug\n",
    "# from icecream import ic\n",
    "# debug = ic\n",
    "import logging\n",
    "logg = logging.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de1961f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, re\n",
    "import argparse\n",
    "import time\n",
    "import random\n",
    "import logging\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch._C import device\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "from modules.train import train\n",
    "from modules.test import test\n",
    "from modules.loader import CustomBamDataset2\n",
    "import utils.utils as util\n",
    "from utils.utils import Parms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a7406ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "root        : INFO     Logger initialized\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser('Train or test SomaticSerum model.')\n",
    "parser.add_argument('training_bam_dir', type=str,\n",
    "                    help='Train data bams directory')\n",
    "parser.add_argument('--sample_split', required=False, type=str,\n",
    "                    help='How to split the training data: True - by samples, False - by random on the entire dataset',\n",
    "                    default = 'True')\n",
    "parser.add_argument('--model', required=False, type=str, \n",
    "                    help='model', default='SimpleCnn')\n",
    "parser.add_argument('--hidden_size', required=False, type=int,\n",
    "                    help='The number of hidden units', default=64)\n",
    "parser.add_argument('--sequence_length', required=False, type=int,\n",
    "                    help='The length of the sequence', default=200)\n",
    "parser.add_argument('--batch_size', required=False, type=int,\n",
    "                    help='The size of each batch', default=512)\n",
    "parser.add_argument('--learning_rate', required=False, type=float,\n",
    "                    help='The learning rate value', default=0.00001)\n",
    "parser.add_argument('--max_epoch', required=False, type=int,\n",
    "                    help='The maximum epoch', default=100)\n",
    "parser.add_argument('--lstm_layers', required=False, type=int,\n",
    "                    help='Num of LSTM layers', default=10)\n",
    "parser.add_argument('--dropout', required=False, type=float,\n",
    "                    help='Dropout', default=0.5)\n",
    "parser.add_argument('--num_workers', required=False, type=int,\n",
    "                    help='Number of workers', default=1)\n",
    "parser.add_argument('--out', required=False, type=str,\n",
    "                    help='Output directory', default='output')\n",
    "parser.add_argument('--test', required=False, type=str,\n",
    "                    help='Test directory')\n",
    "# args = parser.parse_args()\n",
    "\n",
    "args = parser.parse_known_args()[0]\n",
    "args.__dict__.update(dict(\n",
    "#         training_bam_dir=\"../data/seqmerge/DLbams_rand\",\n",
    "        training_bam_dir='/data/alonwolf/projects/SomaticSerum/data/seqmerge/DLbams_rand',\n",
    "        sample_split=True,\n",
    "        model=\"CnnLinear\",\n",
    "        hidden_size=64,\n",
    "        batch_size=2,\n",
    "        learning_rate=0.00001,\n",
    "        max_epoch=100,\n",
    "        dropout=0.005,\n",
    "#         out=MassiveLoop3,\n",
    "    ))\n",
    "parms = Parms(\n",
    "    args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e9dc897",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "root        : INFO     Dataloading train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ../results/output/data_train.pkl exists - using as train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "root        : INFO     Number of Normal reads: 159534, Number of Somatic reads: 168989. Ratio: 0.944\n"
     ]
    }
   ],
   "source": [
    "full_train_dataset  = CustomBamDataset2(parms.BAM_DIR, out = parms.OUT, whichSet = 'train')\n",
    "train_size          = int(parms.TRAIN_VALIDATION_SPLIT * len(full_train_dataset))\n",
    "val_size            = len(full_train_dataset) - train_size\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(full_train_dataset, [train_size, val_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa7b4f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size = parms.BATCH_SIZE, shuffle = True, num_workers = parms.NUM_WORKERS)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size = parms.BATCH_SIZE, shuffle = True, num_workers = parms.NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "762f564a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "root        : INFO     Setting up the model...\n"
     ]
    }
   ],
   "source": [
    "# --- Model setup ----------------------------------------------------\n",
    "logging.info('Setting up the model...')\n",
    "nucleotide_model    = parms.return_model()\n",
    "loss_fn             = torch.nn.CrossEntropyLoss()\n",
    "model_params        = list(nucleotide_model.parameters())\n",
    "optimizer           = torch.optim.AdamW(model_params, lr=parms.LEARNING_RATE, eps=1e-08, weight_decay=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c85a4c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d902414",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "root        : INFO     Setting up the model...\n",
      "root        : INFO     cuda\n",
      "root        : INFO     Training...\n",
      "root        : INFO     train() called: model=CnnLinear, opt=AdamW(lr=0.000010), epochs=100, dropout=0.005000 device=cuda\n",
      "root        : INFO     Epoch   1/100, train loss: 0.6901, train acc: 0.5276, val loss: 0.6844, val acc: 0.5648\n",
      "root        : INFO     Epoch   2/100, train loss: 0.6725, train acc: 0.5846, val loss: 0.6576, val acc: 0.6116\n",
      "root        : INFO     Epoch   3/100, train loss: 0.6298, train acc: 0.6725, val loss: 0.5909, val acc: 0.7285\n",
      "root        : INFO     Epoch   4/100, train loss: 0.5719, train acc: 0.7397, val loss: 0.5555, val acc: 0.7511\n",
      "root        : INFO     Epoch   5/100, train loss: 0.5449, train acc: 0.7635, val loss: 0.5399, val acc: 0.7701\n",
      "root        : INFO     Epoch   6/100, train loss: 0.5387, train acc: 0.7706, val loss: 0.5385, val acc: 0.7677\n",
      "root        : INFO     Epoch   7/100, train loss: 0.5366, train acc: 0.7728, val loss: 0.5363, val acc: 0.7737\n",
      "root        : INFO     Epoch   8/100, train loss: 0.5350, train acc: 0.7744, val loss: 0.5355, val acc: 0.7729\n",
      "root        : INFO     Epoch   9/100, train loss: 0.5335, train acc: 0.7759, val loss: 0.5335, val acc: 0.7766\n"
     ]
    }
   ],
   "source": [
    "# --- Training -------------------------------------------------------\n",
    "logging.info('Setting up the model...')\n",
    "if torch.cuda.is_available():\n",
    "    nucleotide_model = nucleotide_model.cuda()\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "logg(device)\n",
    "\n",
    "if parms.TEST:\n",
    "    # Skip training\n",
    "    logging.info('Skipping train')\n",
    "    metric = pd.read_csv('{}/metric.csv'.format(parms.TEST))\n",
    "    name = '{}/{}'.format(parms.TEST, [f for f in os.listdir(parms.TEST) if f.endswith('.txt')][0].split('txt')[0])\n",
    "    model_path = \"{}/{}.pth\".format(parms.TEST, type(nucleotide_model).__name__)\n",
    "    metric_test = test(parms, model_path, test_dataloader, device, loss_fn)\n",
    "else:\n",
    "    logging.info('Training...')\n",
    "    history, name, metric, model_path = train(model = nucleotide_model,\n",
    "                                optimizer = optimizer,\n",
    "                                loss_fn = loss_fn,\n",
    "                                train_dl = train_dataloader,\n",
    "                                val_dl = valid_dataloader,\n",
    "                                epochs = parms.MAX_EPOCH,\n",
    "                                device = device,\n",
    "                                out = parms.OUT)\n",
    "    # Test\n",
    "    metric_test = test(parms, model_path, test_dataloader, device, loss_fn)\n",
    "\n",
    "# --- Plotting -------------------------------------------------------\n",
    "logging.info('Plotting...')\n",
    "util.plot(name, metric, metric_test, parms.OUT)\n",
    "\n",
    "# acc = history['acc']\n",
    "# val_acc = history['val_acc']\n",
    "# loss = history['loss']\n",
    "# val_loss = history['val_loss']\n",
    "# epochs = range(1, len(acc) + 1)\n",
    "\n",
    "logging.info(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59e04865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.backends.cudnn.enabled = False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
